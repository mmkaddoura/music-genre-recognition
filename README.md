# music-genre-recognition

## Introduction 

MIR (Music Information Retrieval) deals with the analysis of musical content by combining aspects from signal processing, machine learning, and music theory.

MGR (Music Genre Recognition) is a subfield of MIR. Automatic MGR is significant as it enables systems to perform content based music recommendations as well as help organize musical databases.

## Deep Learning Goal

Our overall Deep Learning task is to try come up with a model that performs better on the GTZAN dataset than the majority of other entries.

We are interested in implementing the framework proposed in the paper ["Music Genre Recognition using Deep Neural Networks and Transfer Learning‚Äù](https://www.semanticscholar.org/paper/Music-Genre-Recognition-Using-Deep-Neural-Networks-Ghosal-Kolekar/1efbe96510c16c2d1db9bdba9cfa18464043fb49) by DeepandWay Ghosal and Maheshkumar Kolekar and see if we can recreate the same high accuracy.

## Data

We are using the [GTZAN dataset](https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification).

## Techniques

For our analysis we are interested in implementing a combination of a CNN-LSTM (Convolutional Long Short Term Memory Neural Network) and transfer learning.

LTSM as it is useful for processing entire sequences of data and have an excellent track record with MGR analysis.

Transfer Learning to extract meaningful features from the dataset.

## Requirements 

## How To Run

## Results
